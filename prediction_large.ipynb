{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依赖：\n",
    "# !pip install sentencepiece\n",
    "# !pip install jieba\n",
    "# !pip install regex\n",
    "# !pip install tensorflow\n",
    "# !pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "from gpt2_tokenizer import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "print(hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer(\n",
    "    'CPM-Generate/bpe_3w_new/vocab.json',\n",
    "    'CPM-Generate/bpe_3w_new/merges.txt',\n",
    "    model_file='CPM-Generate/bpe_3w_new/chinese_vocab.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = hub.load('./cpm-large-tf2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(tokenizer, gpt, sentence, number=1, length=20, top_k=50, top_p=0.9, temperature=0.9):\n",
    "    \"\"\"\n",
    "    numbert: 输出句子个数\n",
    "    length: 输出最大长度\n",
    "    top_k: 只选择前k个，如果为0则为无限制\n",
    "    top_p: token的概率排在这以上才有效\n",
    "    temperature: 温度，如果为1.0则相当于无效\n",
    "    \"\"\"\n",
    "    inputs = tf.constant([tokenizer.encode(sentence)] * number, dtype=tf.int64)\n",
    "    length = tf.constant(length, dtype=tf.int64)\n",
    "    ret = gpt.signatures['serving_default'](\n",
    "        inp=inputs,\n",
    "        length=length,\n",
    "        top_k=tf.constant(top_k, tf.int32),\n",
    "        top_p=tf.constant(top_p, tf.float32),\n",
    "        temperature=tf.constant(temperature, tf.float32)\n",
    "    )['output_0']\n",
    "    return [\n",
    "        tokenizer.decode(s).replace(' ', '')\n",
    "        for s in ret.numpy()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问答例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(question):\n",
    "    q = f'''\n",
    "问题：中国首都是哪里？\n",
    "答案：北京\n",
    "问题：美国的首都是哪里？\n",
    "答案：华盛顿\n",
    "问题：李白在哪个朝代？\n",
    "答案：唐朝\n",
    "问题：{question}\n",
    "答案：'''\n",
    "    ret = sample(tokenizer, gpt, q, 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "    answers = []\n",
    "    for x in ret:\n",
    "        a = x[len(q):]\n",
    "        a = a.split('\\n')[0]\n",
    "        answers.append(a)\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.966 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['明代', '明朝', '明代']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('唐伯虎是哪个朝代的人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['尼古拉斯·赵四', '布拉德皮特', '普京']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('世界上最帅的是谁？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['释迦牟尼', '比尔盖茨', '孔子']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('世界上最聪明的人是谁？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['北宋', '北宋', '宋朝']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('李清照是哪个朝代的人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['关公', '关公', '关公']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('关公和秦琼谁厉害？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['卖血', '做一个电视广告', '卖彩票']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('如何赚一百万美元？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['烧烤', '都好吃', '烧烤']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('烧烤和火锅哪个好吃？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['给孩子上课', '小学老师', '成为一个优秀的人']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('如何成为老师？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['鸵鸟', '狗', '考拉']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('佩奇是什么动物？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['几条腿', '象腿', '四条腿']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('大象有几条腿？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['姚明', '1米68', '身高1.78米']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('姚明有多高？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['汤姆', '杰瑞', '汤姆']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('汤姆和杰瑞谁厉害？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['能', '能', '没有人能打过樱桃子']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('野原新之助能打过樱桃子吗？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['哪个都学,不想学的扔', '音乐好', '学习']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('学音乐和学画画哪个好？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中文', '中文', '中文']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('中文和英文哪个难学？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python', 'java', 'python']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('python和java哪个难？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['每天都是', '“谁知盘中餐,粒粒皆', '“谁知盘中餐,粒粒皆']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('“锄禾日当午”的下一句是什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['鸭子', '鸡蛋', '鸭肉']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('烤鸭的主要原料是什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['从左边数第1块,再从右边', '↓↓↓↓↓', '放进冰箱里,放到边上']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('把大象放冰箱总共分几步？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8848', '2944米', '8000米']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('珠穆朗玛峰有多高？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['珠穆朗玛峰', '珠穆朗玛峰', '珠穆朗玛峰']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('世界上最高的山是什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我不知道', '1857万', '1万']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('中国有多少人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['日本有1亿5千万人', '10万人', '日本']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('日本有多少人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['苹果', '苹果', '苹果']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('苹果手机好还是华为手机好？')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小明决定去吃饭,小红继续写作业\n",
      "问题:去吃饭的人是谁?\n",
      "答案:张小红\n",
      "问题:去吃饭的\n",
      "--------------------\n",
      "小明决定去吃饭,小红继续写作业\n",
      "问题:去吃饭的人是谁?\n",
      "答案:吃⁇鱼饺子的人。\n",
      "\n",
      "--------------------\n",
      "小明决定去吃饭,小红继续写作业\n",
      "问题:去吃饭的人是谁?\n",
      "答案:小明\n",
      "小红:“你”\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '小明决定去吃饭，小红继续写作业\\n问题：去吃饭的人是谁？\\n答案：', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 英文问答例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟bird\n",
      "。。。\n",
      "--------------------\n",
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟bird\n",
      "鱼fish\n",
      "\n",
      "--------------------\n",
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟bird\n",
      "猫cat\n",
      "海\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '默写英文：\\n狗dog\\n猫cat\\n鸟', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 默写古诗例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "举头望\n",
      "--------------------\n",
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "举头望\n",
      "--------------------\n",
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "举头望\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '默写古诗：\\n白日依山尽，黄河入海流。\\n床前明月光，', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不同的角色对话生成例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“你说了多少次了,我不是来找你算账的,而是\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“他们走了,我还不走呢!”\n",
      "佟湘\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“我说掌柜的,你是哪根葱,怎么就不长眼呢,\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n佟掌柜：“', 3, 20, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“走了!”\n",
      "张晋生:“那我也走了\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“白展堂你说啥?”\n",
      "李大嘴:“我\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“我也没话了,你俩别走了,回房去吧。\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n白展堂：“', 3, 20, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“去哪啊?”\n",
      "张菁:“他们说的有\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“我是,我是,我没碰见你,你走!”\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“你还敢去找郭芙蓉?”\n",
      "小贝:“你\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n莫小贝：“', 3, 20, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“各位兄弟,咱们还是喝酒,继续说大话吧!”\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“李白,你又不是说了,咱们不可以在这里说话,\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“这次要是再有什么事,老妹子我可不敢一个人活了\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n李白：“', 3, 20, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问答的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是华盛顿\n",
      "印度\n",
      "--------------------\n",
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是华盛顿\n",
      "法国\n",
      "--------------------\n",
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是华盛顿\n",
      "法国\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '中国的首都是北京\\n日本的首都是东京\\n美国的首都是', 3, 3, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是明\n",
      "--------------------\n",
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是明\n",
      "--------------------\n",
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是元\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李白所在朝代是唐\\n李清照所在朝代是宋\\n唐伯虎所在朝代是', 3, 1, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "陈奕迅是歌星\n",
      "郭德纲是江湖大哥\n",
      "--------------------\n",
      "陈奕迅是歌星\n",
      "郭德纲是相声演员\n",
      "--------------------\n",
      "陈奕迅是歌星\n",
      "郭德纲是相声大师\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '陈奕迅是歌星\\n郭德纲是', 3, 1, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "珠穆朗玛峰的高度(米)是3227m,珠穆朗玛峰的\n",
      "--------------------\n",
      "珠穆朗玛峰的高度(米)是在地球表面的海平面上的最低\n",
      "--------------------\n",
      "珠穆朗玛峰的高度(米)是8848。[6]\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '珠穆朗玛峰的高度（米）是', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "姚明的身高(米)是5218.63千克\n",
      "--------------------\n",
      "姚明的身高(米)是1.82米,在NBA里是\n",
      "--------------------\n",
      "姚明的身高(米)是七米,你把你的体重(公\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '姚明的身高（米）是', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算数例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=8\n",
      "--------------------\n",
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=8\n",
      "--------------------\n",
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=8\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '1+1=2\\n2+2=4\\n3+3=6\\n4+4=', 3, 1, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=5\n",
      "--------------------\n",
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=5\n",
      "--------------------\n",
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=5\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '1+1=2\\n1+2=3\\n1+3=4\\n1+4=', 3, 1, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ???的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "紫雷这通天玄铁\n",
      "三清宝座\n",
      "三清道人\n",
      "三清天尊\n",
      "三清长老\n",
      "--------------------\n",
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "青锋这青耀刀\n",
      "红雾这玄冰银戟\n",
      "玄冰这玄霜银戟\n",
      "玄霜这玄霜\n",
      "--------------------\n",
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "紫金锤这天地器\n",
      "天地器这天地道\n",
      "紫电这玄真火焰\n",
      "紫金锤这天地\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '''惊雷这通天修为\n",
    "天塌地陷紫金锤\n",
    "紫电这玄真火焰\n",
    "''', 3, 30, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 写作文例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爱情是不一样的,但前提是你知道你到底想要什么。<eod>诗词:⁇鹊声中欲别时,行云片片近高楼,芳情荏苒\n",
      "--------------------\n",
      "爱情是不能勉强的,否则你将失去一个对的人,也失去一段美好的回忆。可能我会在某个适当的时候里接受你,共度一生。(我知道\n",
      "--------------------\n",
      "爱情是对等的,付出和收获是对等的,不是你想做什么就能做什么,不是你想爱谁就能爱谁,不是你想和谁在一起就能和谁在一起\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '''爱情是''', 3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。遂同众嬷嬷说笑,一直到穿堂后面的大厅里,方才坐了。王夫人便命将大厅收拾出来,黛玉笑说:“我知道了。”——《红楼梦》—————————————————————————————————————————————————————————————————\n",
      "--------------------\n",
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。黛玉⁇了两步,便往东而去。这时正值太阳在西,光焰万丈,也就只有那西边不远,照着四围,明晃晃的一大片。林黛玉知道这是正照到西边,甬路的东边是上房,西边是东西房,岔了岔,向南便是个上房,便急忙往南而去。黛玉便径往上房去,到了上房,只见里面一室四间,都是彩画纱窗,金砖铺地,并无纤尘,只有一色绫绮,案上设着珍玩,架上琳琅,连天上的星河也有,还有几个鲛人泪\n",
      "--------------------\n",
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。黛玉进了正房,但见里面轩窗密槛,案上仪制,俱是上等陈设,地下铺设的是金砖银瓦,堂内陈设陈设,更比先时不同。黛玉便叫小丫头倒了茶来,黛玉亲自⁇了一杯,笑道:“这些东西,虽值万钱,还没有一个我见过的。”小丫头笑道:“这是宝姐姐的东西,那里是我的。”黛玉道:“我才不稀罕呢。”一面说,一面将手内的那盏茶,朝案上只一放。众嬷嬷忙都闪开,笑道:“那有什么稀罕的,只怕\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    '''一时黛玉进了荣府，下了车。众嬷嬷引着，便往东转弯，穿过一个东西的穿堂，向南大厅之后，仪门内大院落，上面五间大正房，两边厢房鹿顶耳房钻山，四通八达，轩昂壮丽，比贾母处不同。黛玉便知这方是正经正内室，一条大甬路，直接出大门的。''',\n",
    "    3, 200, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对话例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:“今天我想吃火锅”\n",
      "B:“那吃火锅怎么不喝酒?”\n",
      "A:“那吃火锅怎么不喝酒?”\n",
      "B:“那吃火锅怎么不喝酒?”\n",
      "A:“\n",
      "--------------------\n",
      "A:“今天我想吃火锅”\n",
      "B:“我不喜欢吃火锅”\n",
      "A:“哦,那是因为你一个人吃火锅吗?”\n",
      "B:“不是,是因为我有病。”\n",
      "\n",
      "--------------------\n",
      "A:“今天我想吃火锅”\n",
      "B:“我今天不想吃火锅”\n",
      "A:“那怎么办?”\n",
      "B:“你说咋办?”\n",
      "A:“我说我不想吃火锅”\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    '''A：“今天我想吃火锅”\n",
    "B：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:“跟我一起去看电影吧”\n",
      "B:“那你喜欢看什么电影?”\n",
      "A:“其实我不太喜欢看电影,以前也没怎么看过”\n",
      "B:“那我给你推荐几个吧\n",
      "--------------------\n",
      "A:“跟我一起去看电影吧”\n",
      "B:“我要去吃面”\n",
      "A:“那你自己去吧”\n",
      "B:“那我跟你一起去看电影吧”\n",
      "A:“我要去吃\n",
      "--------------------\n",
      "A:“跟我一起去看电影吧”\n",
      "B:“你的A片看过了,B片我都没看过,一起去看吧”\n",
      "A:“好,我跟你一起去看电影吧”\n",
      "B:\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''A：“跟我一起去看电影吧”\n",
    "B：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对联例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "duilian = '''\n",
    "上联天，下联地\n",
    "上联雨，下联风\n",
    "上联大陆，下联长空\n",
    "上联雷隐隐，下联雾蒙蒙\n",
    "上联开心大吉，下联万事亨通\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联张大千作\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联王昭君\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联杜甫作诗\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联杜甫作诗\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联扬子\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联李白作诗，下联',\n",
    "    5, 2, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联追求快乐\n",
      "上\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联追求幸福\n",
      "上\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联家徒四壁\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联平安幸福\n",
      "上\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联平安\n",
      "上联\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联追求真爱，下联',\n",
    "    5, 4, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联⁇⁇\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联夜夜欢歌\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联天天平安\n",
      "上\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联平平安安\n",
      "\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联天天开心\n",
      "上\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联天天向上，下联',\n",
    "    5, 4, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联我的心里全是你\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联我与天地长存\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联世界在我心中\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联世界在我脚\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联世间事\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联天地在我心，下联',\n",
    "    5, 4, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 名人名言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鲁迅曾经说过:“中国就如一只船,只是有人看到了它的航向,却没有人知道它的归宿。”对于未来,他也在探索,“不知道自己的\n",
      "--------------------\n",
      "鲁迅曾经说过:“中国人一向就有喝茶的习惯,但喝茶的习惯,还是从日本传来的。”茶的饮用,在古时是为了提神,在后来却成为一种身份\n",
      "--------------------\n",
      "鲁迅曾经说过:“每个人都是一座孤岛,只能在大海里漂浮,除了拼命,别无他途。”鲁迅先生这句话是说,因为时代不同,每个\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''鲁迅曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爱因斯坦曾经说过:“哲学家们只是用不同的方式解释世界,而问题在于改变世界。”哲学家不关心世界是怎么样的,而只是世界应该是什么样子。当然\n",
      "--------------------\n",
      "爱因斯坦曾经说过:“如果我把我的脑袋放在一只桶里,在桶里放了一块石头,当我要扔掉石头的时候,它会自动浮起来。”当然,爱因斯坦\n",
      "--------------------\n",
      "爱因斯坦曾经说过:“给我一个支点,我将撬起整个地球。”这种信念和精神已经深深地烙在了中国人的身上。我们要以这种精神为指针\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''爱因斯坦曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "牛顿曾经说过:“一个哲学家在思考的时候,他的眼里不应该只有存在,还应该有不存在。”这句话我一直深以为然。那存在到底是什么呢\n",
      "--------------------\n",
      "牛顿曾经说过:“我们的感官无法达到的地方,数学是永远无法解释的。”而现在,数学已经可以解释部分我们所能知道的事情,比如数学中的高斯分布,比如\n",
      "--------------------\n",
      "牛顿曾经说过:“没有一个科学理论是完备的,而只有一个理论是不完备的。”这句话的意思就是说,不完备的理论是一种尚未证明的假说,而完备的理论\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''牛顿曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "佛祖曾经说过:“佛祖如来是过来人,人在做,天在看,我也是过来人,我知道人在江湖身不由己,我就更要把握好度,更要活出\n",
      "--------------------\n",
      "佛祖曾经说过:“以色侍人者,色衰而爱弛;以音侍人者,声浊而爱绝。”我想,真正爱到可以为她抛弃一切的人,\n",
      "--------------------\n",
      "佛祖曾经说过:“汝等且看他是谁?”如来佛祖说:“我看他是大梵天。”大梵天说:“他是天宫里\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''佛祖曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "乔布斯曾经说过:“在这个世界上,你不需要iPhone,你只需要iPodtouch。”于是,他们就去做了。之后的故事,大家都\n",
      "--------------------\n",
      "乔布斯曾经说过:“如果你能坚持一个看法10年,你就会成为这个领域最出色的人。”这句话说的很对,我想知道那些看到这句话后坚持下来\n",
      "--------------------\n",
      "乔布斯曾经说过:“他们的成功是不可复制的,也是不可模仿的。”\n",
      "《硅谷禁书》描述了乔布斯的很多趣事,包括为了省下钱而将钱\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''乔布斯曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
