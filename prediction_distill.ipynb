{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依赖：\n",
    "# !pip install sentencepiece\n",
    "# !pip install jieba\n",
    "# !pip install regex\n",
    "# !pip install tensorflow\n",
    "# !pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "from gpt2_tokenizer import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "print(hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer(\n",
    "    'CPM-Generate/bpe_3w_new/vocab.json',\n",
    "    'CPM-Generate/bpe_3w_new/merges.txt',\n",
    "    model_file='CPM-Generate/bpe_3w_new/chinese_vocab.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = hub.load('./cpm-distill-tf2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(tokenizer, gpt, sentence, number=1, length=20, top_k=50, top_p=0.9, temperature=0.9):\n",
    "    \"\"\"\n",
    "    numbert: 输出句子个数\n",
    "    length: 输出最大长度\n",
    "    top_k: 只选择前k个，如果为0则为无限制\n",
    "    top_p: token的概率排在这以上才有效\n",
    "    temperature: 温度，如果为1.0则相当于无效\n",
    "    \"\"\"\n",
    "    inputs = tf.constant([tokenizer.encode(sentence)] * number, dtype=tf.int64)\n",
    "    length = tf.constant(length, dtype=tf.int64)\n",
    "    ret = gpt.signatures['serving_default'](\n",
    "        inp=inputs,\n",
    "        length=length,\n",
    "        top_k=tf.constant(top_k, tf.int32),\n",
    "        top_p=tf.constant(top_p, tf.float32),\n",
    "        temperature=tf.constant(temperature, tf.float32)\n",
    "    )['output_0']\n",
    "    return [\n",
    "        tokenizer.decode(s).replace(' ', '')\n",
    "        for s in ret.numpy()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问答例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(question):\n",
    "    q = f'''\n",
    "问题：中国首都是哪里？\n",
    "答案：北京\n",
    "问题：美国的首都是哪里？\n",
    "答案：华盛顿\n",
    "问题：李白在哪个朝代？\n",
    "答案：唐朝\n",
    "问题：{question}\n",
    "答案：'''\n",
    "    ret = sample(tokenizer, gpt, q, 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "    answers = []\n",
    "    for x in ret:\n",
    "        a = x[len(q):]\n",
    "        a = a.split('\\n')[0]\n",
    "        answers.append(a)\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.074 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['宋朝', '宋朝', '明朝']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('唐伯虎是哪个朝代的人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['唐太宗', '中国著名的帝王', '毛泽东']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('世界上最帅的是谁？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['希腊', '德国', '罗马']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('世界上最聪明的人是谁？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['白族', '清代', '清朝']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('李清照是哪个朝代的人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['宋江', '赵飞燕和李逵谁厉害?', '唐朝']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('关公和秦琼谁厉害？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['华盛顿', '法国', '美国的首都是哪里?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('如何赚一百万美元？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['⁇鱼', '北京', '川菜']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('烧烤和火锅哪个好吃？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['李白', '孔子', '唐诗']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('如何成为老师？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“乌龟”', '俄罗斯', '孔雀']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('佩奇是什么动物？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['美国', '印度', '唐朝']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('大象有几条腿？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['姚明能登上奥运会!', '刘翔和刘翔的差距', '姚明']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('姚明有多高？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['约翰逊', '谁厉害?', '“杰克”']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('汤姆和杰瑞谁厉害？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['曹操', '日本', '李白的诗写得很好']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('野原新之助能打过樱桃子吗？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中国美术馆', '《四平调》', '钢琴']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('学音乐和学画画哪个好？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中文', '明朝', '中文和英文哪个容易?']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('中文和英文哪个难学？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['java', 'python', 'yahoo']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('python和java哪个难？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['唐', '“君子不器”', '“锄禾日当午”的']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('“锄禾日当午”的下一句是什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['烤鸭的主要原料是什么?', '生食', '新疆']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('烤鸭的主要原料是什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['皇帝', '唐朝', '美国的首都是哪里?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('把大象放冰箱总共分几步？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中国南边有多远?', '青藏高原有多高?', '香港']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('珠穆朗玛峰有多高？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['月球', '埃及', '美国的最高峰是巴黎']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('世界上最高的山是什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['日本', '北京', '《史记》']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('中国有多少人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['元朝', '明朝', '中华民国']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('日本有多少人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['三星', '三星', '努比亚']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('苹果手机好还是华为手机好？')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小明决定去吃饭,小红继续写作业\n",
      "问题:去吃饭的人是谁?\n",
      "答案:那个人是你朋友,小红想帮他\n",
      "--------------------\n",
      "小明决定去吃饭,小红继续写作业\n",
      "问题:去吃饭的人是谁?\n",
      "答案:是:小红。\n",
      "问题二\n",
      "--------------------\n",
      "小明决定去吃饭,小红继续写作业\n",
      "问题:去吃饭的人是谁?\n",
      "答案:一个叫朱一超的小男孩\n",
      "问题\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '小明决定去吃饭，小红继续写作业\\n问题：去吃饭的人是谁？\\n答案：', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 英文问答例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟cat\n",
      "羊cat\n",
      "......\n",
      "--------------------\n",
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟cat\n",
      "鼠cat\n",
      "\n",
      "--------------------\n",
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟grand\n",
      "秃鹫grand\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '默写英文：\\n狗dog\\n猫cat\\n鸟', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 默写古诗例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "夜来幽\n",
      "--------------------\n",
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "举头望\n",
      "--------------------\n",
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "谁道\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '默写古诗：\\n白日依山尽，黄河入海流。\\n床前明月光，', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不同的角色对话生成例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“谁家没事?”\n",
      "佟掌柜:“谁家没\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“......”\n",
      "杨大嘴:“我这个老太太\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“唉!”\n",
      "佟掌柜:“您可知道小老\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n佟掌柜：“', 3, 20, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“是!”\n",
      "白展堂:“兄台......\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“回去!”\n",
      "白展堂:“我知道了!\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“我不是他们的人,我自己有本事做官,但谁也不能\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n白展堂：“', 3, 20, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“我哪敢跟你说话,那是我爸妈,我......”\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“我也不知道我这个人,都是你说了算。”\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“大姐,你怎么就这么讨厌,这事儿我倒没想。”\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n莫小贝：“', 3, 20, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“咱们去看看,让那个⁇子手知道不。”\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“行去!”\n",
      "吕光:“去!”\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“老李,你听我的!”\n",
      "李白:“谁\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n李白：“', 3, 20, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问答的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是纽约\n",
      "英国\n",
      "--------------------\n",
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是纽约\n",
      "新加坡\n",
      "--------------------\n",
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是纽约\n",
      "香港\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '中国的首都是北京\\n日本的首都是东京\\n美国的首都是', 3, 3, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是宋\n",
      "--------------------\n",
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是宋\n",
      "--------------------\n",
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是北宋\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李白所在朝代是唐\\n李清照所在朝代是宋\\n唐伯虎所在朝代是', 3, 1, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "陈奕迅是歌星\n",
      "郭德纲是艺人\n",
      "--------------------\n",
      "陈奕迅是歌星\n",
      "郭德纲是相声演员\n",
      "--------------------\n",
      "陈奕迅是歌星\n",
      "郭德纲是相声演员\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '陈奕迅是歌星\\n郭德纲是', 3, 1, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "珠穆朗玛峰的高度(米)是世界最低的,海拔高度为778米\n",
      "--------------------\n",
      "珠穆朗玛峰的高度(米)是1260米,最高峰是2220米\n",
      "--------------------\n",
      "珠穆朗玛峰的高度(米)是5500米,高度(米)是\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '珠穆朗玛峰的高度（米）是', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "姚明的身高(米)是多少?-体育\n",
      "--------------------\n",
      "姚明的身高(米)是有什么用?本题已加入知乎\n",
      "--------------------\n",
      "姚明的身高(米)是球员能够保持的最大高度。\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '姚明的身高（米）是', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算数例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=7\n",
      "--------------------\n",
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=7\n",
      "--------------------\n",
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=7\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '1+1=2\\n2+2=4\\n3+3=6\\n4+4=', 3, 1, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=5\n",
      "--------------------\n",
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=5\n",
      "--------------------\n",
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=5\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '1+1=2\\n1+2=3\\n1+3=4\\n1+4=', 3, 1, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ???的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "七种神通\n",
      "一锤爆开\n",
      "天崩地陷\n",
      "天翻地陷\n",
      "天崩地陷\n",
      "天崩\n",
      "--------------------\n",
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "天地灵兽\n",
      "兵戈剑戟\n",
      "战歌如歌战歌\n",
      "大帝神剑\n",
      "雷锋宝剑\n",
      "\n",
      "--------------------\n",
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "化作了“九阳”\n",
      "“九阳”\n",
      "轰隆隆\n",
      "“九阳”\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '''惊雷这通天修为\n",
    "天塌地陷紫金锤\n",
    "紫电这玄真火焰\n",
    "''', 3, 30, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 写作文例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爱情是多么美好,对每个人都是多么的可贵。<eod>如何评价魅族官方声称会「上榜」?@魅族产品设计总监兼首席设计师@\n",
      "--------------------\n",
      "爱情是什么?我的第一个女朋友,比我大三岁,也比我小。她有个超级可爱的男朋友,而我只有初恋。她\n",
      "--------------------\n",
      "爱情是可以去学习的,但是你只有在学习了才有机会去恋爱,但是你对自己很负责,你有能力去选择如何去爱自己,而不是因为别人说什么就去改变\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '''爱情是''', 3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。黛玉便知,宝姐姐们已经住下了。这方正房内,放着凤姐、凤姐姐的黛玉梳妆台、扇子、茶杯、床。走到第二间大院落,门口有一牌楼,牌楼上的牌写的是:“黛玉睡在槛里”。这里,也是凤姐、凤姐姐的黛玉梳妆台、扇子、茶杯、床。进去,黛玉看见那扇子,便上前,说道:“小的们叫道:‘小的坐这里,你我这里坐!’”说着,便从怀里取出一张纸来,向宝玉的怀里一揣\n",
      "--------------------\n",
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。众人还不明白这是何事,先有人说:“这里角缝小些,待会儿有火盆子,就可以烧了。”黛玉道:“烧上,我就不进去了。”只见曹雪芹的正房三间,每间都有火盆子,黛玉便有了准备。王夫人道:“这里是我家主客厅,你先别进去,你有了铺盖,就把灯打开,说一声,道一声,‘好’。”宝玉听了,便在前头,道一声“好”。众人听了,皆侧目,道:“这才是好\n",
      "--------------------\n",
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。黛玉进来,进内室,见门是小门,里面有门,门里开着的是书案,旁边是书柜,里面是书架,架子上是几册《红楼梦》,几册《金瓶梅》,还有几册《脂砚斋重评红楼》。黛玉道:“看这书,也是小道儿写的。这书可得瞧瞧。”那里厢房里说道:“瞧瞧去。”黛玉便瞧那书架,说道:“有几卷,我却不知这书影。”便叫道:“你就在那里,快看。”那书影也跟着瞧了,不知怎么\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    '''一时黛玉进了荣府，下了车。众嬷嬷引着，便往东转弯，穿过一个东西的穿堂，向南大厅之后，仪门内大院落，上面五间大正房，两边厢房鹿顶耳房钻山，四通八达，轩昂壮丽，比贾母处不同。黛玉便知这方是正经正内室，一条大甬路，直接出大门的。''',\n",
    "    3, 200, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对话例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:“今天我想吃火锅”\n",
      "B:“什么火锅”\n",
      "C:“......”\n",
      "D:“我想吃辣”\n",
      "E:“我很喜欢辣”\n",
      "F:“我喜\n",
      "--------------------\n",
      "A:“今天我想吃火锅”\n",
      "B:“没事,就是我自己想吃火锅”\n",
      "C:“我知道我一个人吃火锅的时候,会吃到很多不一样的味道,但是我没有这么说过”\n",
      "\n",
      "--------------------\n",
      "A:“今天我想吃火锅”\n",
      "B:“不行,去吃火锅吧”\n",
      "C:“去吃火锅吧”\n",
      "D:“行,那我去吃麻辣烫吧”\n",
      "E:“来\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    '''A：“今天我想吃火锅”\n",
    "B：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:“跟我一起去看电影吧”\n",
      "B:“真的,我知道,我会带你去看电影的”\n",
      "A:“好,那你怎么办?”\n",
      "B:“我也不知道,我觉得\n",
      "--------------------\n",
      "A:“跟我一起去看电影吧”\n",
      "B:“好的”\n",
      "A:“......”\n",
      "B:“你跟我走吧”\n",
      "A:“......”\n",
      "B:“......”\n",
      "--------------------\n",
      "A:“跟我一起去看电影吧”\n",
      "B:“好”\n",
      "A:“去了?”\n",
      "B:“啊,真的”\n",
      "A:“你什么意思”\n",
      "B:“我想不出\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''A：“跟我一起去看电影吧”\n",
    "B：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对联例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "duilian = '''\n",
    "上联天，下联地\n",
    "上联雨，下联风\n",
    "上联大陆，下联长空\n",
    "上联雷隐隐，下联雾蒙蒙\n",
    "上联开心大吉，下联万事亨通\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联宋诗\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联安邦治\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联李白作诗\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联多情\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联笑颜\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联李白作诗，下联',\n",
    "    5, 2, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联只爱我一人\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联万事兴\n",
      "上\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联义无返顾\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联待你来\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联人人有福\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联追求真爱，下联',\n",
    "    5, 4, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联颂一声\n",
      "\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联天天平安\n",
      "上\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联人人幸福\n",
      "上\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联兴旺发达\n",
      "\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联小赌怡情\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联天天向上，下联',\n",
    "    5, 4, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联欢天喜地\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联法力腾\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联万事如意\n",
      "\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联鹏程万里\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联我自在逍遥\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联天地在我心，下联',\n",
    "    5, 4, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 名人名言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鲁迅曾经说过:“‘不讲这一套,我们就没有事情做。’我的意思是,要想到自己的使命,不讲一套,我们就什么都没有做。”\n",
      "--------------------\n",
      "鲁迅曾经说过:“不信上帝的人,死也不能复活。”可见耶稣和耶稣教堂、耶稣会堂、天主教堂、犹太教堂等基督教堂的地位实在是远远超越了犹太\n",
      "--------------------\n",
      "鲁迅曾经说过:“‘观者莫若观,观者莫若观’”。在《新唐书·玄宗纪》中,李辅国就说:“昔\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''鲁迅曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爱因斯坦曾经说过:“科学家的使命在于发现真理。”而科学家的使命,恰恰是探索真相。如果不了解真实的世界,科学家就无法探索出真实的宇宙。\n",
      "--------------------\n",
      "爱因斯坦曾经说过:“我对过去的事情并不了解,我不知道以后会发生什么。”如果你问:“你有可能在任何时候去自杀,这是真的吗?”\n",
      "--------------------\n",
      "爱因斯坦曾经说过:“你在艺术家面前是个骗子。”正如他在一次著名的演讲中所说:“你很少在艺术家面前提起艺术家。”为什么说\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''爱因斯坦曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "牛顿曾经说过:“我们在这个世界上,‘生活在’在这个世界上。”但事实是,这并不是我们的错。在这个世界上,我们不应该\n",
      "--------------------\n",
      "牛顿曾经说过:“我们的祖先就知道了动物,因此我们只能说那些动物不知道的事。”但是,我们的祖先也不知道。达尔文的进化论(达尔文进化论)\n",
      "--------------------\n",
      "牛顿曾经说过:“人类社会是一种大灾难,它是地球对太阳的‘保护’。地球上的‘大灾难’是一个‘大\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''牛顿曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "佛祖曾经说过:“不信,那种书,可以随便看看。”我就找了一本,看了十几页,还不认识,只有一个字:“完!”我\n",
      "--------------------\n",
      "佛祖曾经说过:“佛祖的话,虽然好像有些微言大义,其实也就那样。”可见,佛祖教我们做人,既要信则有信,不信则无,\n",
      "--------------------\n",
      "佛祖曾经说过:“有了德性,没有了智性,无论多么贫瘠的土地,都有了温暖的、令人满意的天空。”说这句话时,也不忘了提醒\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''佛祖曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "乔布斯曾经说过:“美国人是不懂得他们的文化的。”[21]在此情况下,威廉·阿伦特在解释自己的观点时说:“美国人比我们\n",
      "--------------------\n",
      "乔布斯曾经说过:“那些话不是人说的,是说你的。”我也是从这里学会了一些该怎么做。接下来要做的就是如何去面对恐惧。\n",
      "--------------------\n",
      "乔布斯曾经说过:“我们可以找到一种方法,就是用自己的语言将自己的思想通过对方的语言表达出来。”这个方法就是语言学习的关键。当你的词汇量达到一定程度\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''乔布斯曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
